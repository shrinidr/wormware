{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1lIUETXfHl6"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb)\n",
        "\n",
        "Install the wormpose package if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-JXze3oqfHl-",
        "outputId": "3dd5c5a8-7847-4b27-acc9-92e879e20243",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wormpose\n",
            "  Downloading wormpose-1.3.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from wormpose) (4.12.0.88)\n",
            "Requirement already satisfied: tensorflow>=2 in /usr/local/lib/python3.12/dist-packages (from wormpose) (2.19.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from wormpose) (2.0.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from wormpose) (3.14.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from wormpose) (1.16.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2->wormpose) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2->wormpose) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2->wormpose) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2->wormpose) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2->wormpose) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2->wormpose) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2->wormpose) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2->wormpose) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2->wormpose) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2->wormpose) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2->wormpose) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2->wormpose) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2->wormpose) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2->wormpose) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2->wormpose) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2->wormpose) (1.75.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2->wormpose) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2->wormpose) (3.10.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2->wormpose) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow>=2->wormpose) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=2->wormpose) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=2->wormpose) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=2->wormpose) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow>=2->wormpose) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow>=2->wormpose) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow>=2->wormpose) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow>=2->wormpose) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=2->wormpose) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=2->wormpose) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=2->wormpose) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow>=2->wormpose) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow>=2->wormpose) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow>=2->wormpose) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=2->wormpose) (0.1.2)\n",
            "Downloading wormpose-1.3.0-py3-none-any.whl (22.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wormpose\n",
            "Successfully installed wormpose-1.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade wormpose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWaFZqi6fHmA"
      },
      "source": [
        "If using Google Colab, please **restart the runtime** after installing the package: menu \"Runtime\" > \"Restart runtime\".\n",
        "\n",
        "You can also select a GPU node for faster training: menu \"Runtime\" > \"Change Runtime Type\" > select \"GPU\" in the menu \"Hardware Accelerator\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AUGcI1wfHmB"
      },
      "source": [
        "We first download some utility functions to display images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_c4Eo9JmfHmC",
        "outputId": "1415755e-c4da-4539-8479-b322a66a84af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-29 03:23:23--  https://raw.githubusercontent.com/iteal/wormpose/main/examples/ipython_utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1721 (1.7K) [text/plain]\n",
            "Saving to: ‘ipython_utils.py’\n",
            "\n",
            "ipython_utils.py    100%[===================>]   1.68K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-09-29 03:23:23 (18.1 MB/s) - ‘ipython_utils.py’ saved [1721/1721]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/iteal/wormpose/main/examples/ipython_utils.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBtAnYAgfHmC"
      },
      "source": [
        "## Download sample data\n",
        "\n",
        "The sample data is composed of a set of images and a h5 file containing the features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "V_1IahG_fHmD",
        "outputId": "1027da97-eea8-4fd1-eace-693ad9605a7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'wormpose_data'...\n",
            "remote: Enumerating objects: 1101, done.\u001b[K\n",
            "remote: Counting objects: 100% (45/45), done.\u001b[K\n",
            "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
            "remote: Total 1101 (delta 7), reused 0 (delta 0), pack-reused 1056 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1101/1101), 64.02 MiB | 14.22 MiB/s, done.\n",
            "Resolving deltas: 100% (20/20), done.\n"
          ]
        }
      ],
      "source": [
        "sample_data_root = 'wormpose_data'\n",
        "import os, shutil\n",
        "if os.path.exists(sample_data_root):\n",
        "    shutil.rmtree(sample_data_root)\n",
        "os.mkdir(sample_data_root)\n",
        "!git clone https://github.com/iteal/wormpose_data.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hatzXfOkfHmE"
      },
      "source": [
        "## Set inputs\n",
        "\n",
        "We load the sample data dataset using the \"sample_data\" default loader, and set the path of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aDBLA_HXfHmF",
        "outputId": "ee65f59e-0e13-4758-c4d6-9cacac3015cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using the default dataset loader: 'sample_data', to load the sample dataset images and labels,\n",
            " from the folder 'wormpose_data/datasets/sample_data'.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from wormpose.config import default_paths\n",
        "from wormpose.dataset.loader import load_dataset\n",
        "\n",
        "# We have different loaders for different datasets, we use \"sample_data\" for the tutorial data,\n",
        "# replace with \"tierpsy\" for Tierpsy tracker data, or with your custom dataset loader name\n",
        "dataset_loader = \"sample_data\"\n",
        "\n",
        "# Set the path to the dataset,\n",
        "# for Tierpsy tracker data this will be the root path of a folder containing subfolders for each videos\n",
        "dataset_path = \"wormpose_data/datasets/sample_data\"\n",
        "\n",
        "print(f\"Using the default dataset loader: \\'{dataset_loader}\\', to load the sample dataset images and labels,\\n from the folder \\'{dataset_path}\\'.\\n\")\n",
        "dataset_root_name = os.path.basename(os.path.normpath(dataset_path))\n",
        "project_dir = os.path.join(default_paths.WORK_DIR, dataset_root_name)\n",
        "\n",
        "# Set if the worm is lighter than the background in the image\n",
        "# in the sample data, the worm is darker so we set this variable to False\n",
        "worm_is_lighter = False\n",
        "\n",
        "# This function loads the dataset\n",
        "# optional fields: there is an optional resize parameter to resize the images\n",
        "# also you can select specific videos from the dataset instead of loading them all\n",
        "dataset = load_dataset(dataset_loader, dataset_path, worm_is_lighter=worm_is_lighter)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.num_frames"
      ],
      "metadata": {
        "id": "kfqX86zwhA4X",
        "outputId": "9e46766a-6931-49f0-d20b-753b1b858c7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Dataset.num_frames of <wormpose.dataset.loader.Dataset object at 0x7eae748b8d70>>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>wormpose.dataset.loader.Dataset.num_frames</b><br/>def num_frames(video_name)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/wormpose/dataset/loader.py</a>&lt;no docstring&gt;</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 42);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1W8rScyMfHmG"
      },
      "source": [
        "### Visualize the raw dataset images\n",
        "\n",
        "First, we simply display the first 100 frames of the first video the dataset. These are the raw dataset images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fDyae6frfHmG",
        "outputId": "35e7d574-7660-4200-a777-27dd90e51842",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108,
          "referenced_widgets": [
            "2d34e474e64b417baac08d5d1025a19c",
            "e358278709564ac1b16aaa42f8814595",
            "a7fd41eeac3544088bbf8728d2f07773",
            "e657ebcd1dcb4559a8ab951a4f9a7db0",
            "0175055e87c547e895342cd562fd765a",
            "85a0833976d643a3aa3fa2396f487269",
            "8ad54750071a4514bad4a592475f7065"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "interactive(children=(IntSlider(value=0, description='index', max=99), Output()), _dom_classes=('widget-intera…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d34e474e64b417baac08d5d1025a19c"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from ipython_utils import ImagesViewer\n",
        "\n",
        "MAX_FRAMES = 100\n",
        "img_viewer = ImagesViewer()\n",
        "\n",
        "video_name = dataset.video_names[0]\n",
        "with dataset.frames_dataset.open(video_name) as frames:\n",
        "    for frame in frames[:MAX_FRAMES]:\n",
        "        img_viewer.add_image(frame)\n",
        "\n",
        "img_viewer.view_as_slider()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBuiuhNKfHmH"
      },
      "source": [
        "### Visualize the synthetic images\n",
        "\n",
        "The postures model generates worm postures, that we can use to draw a synthetic image representing that posture.\n",
        "You can run the cell below to visualize a small sample of such generated images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-4pnTF85fHmH",
        "outputId": "45442a23-271c-457e-814f-5d147ff3a029",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1665304114.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mipython_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImagesViewer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_as_slider\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m synth_viz = SyntheticSimpleVisualizer(dataset_loader,\n\u001b[0m\u001b[1;32m      8\u001b[0m                                       \u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                       worm_is_lighter=worm_is_lighter).generate()\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wormpose/demo/synthetic_simple_visualizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset_loader, dataset_path, postures_generator, video_name, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_image_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         self.synthetic_dataset = SyntheticDataset(\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mframe_preprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_preprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0moutput_image_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_image_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wormpose/images/synthetic/synthetic_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, frame_preprocessing, enable_random_augmentations, output_image_shape)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calc_all_coords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_synth_worm_measurements_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worm_outline_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWormOutlineMask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_image_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_frames_infos_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_patch_drawing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPatchDrawing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_image_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_image_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wormpose/images/synthetic/_helpers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, output_image_shape)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_image_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_worm_body\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_draw_worm_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_shape_outline_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_image_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wormpose/images/worm_drawing.py\u001b[0m in \u001b[0;36mmake_draw_worm_body\u001b[0;34m(body_color)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m#  preallocates some internal data structures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mpolygon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0morthogonal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mvertices_todraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mcur_joint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m__former_attrs__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__former_attrs__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m__expired_attributes__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import tempfile\n",
        "from wormpose.demo.synthetic_simple_visualizer import SyntheticSimpleVisualizer\n",
        "from ipython_utils import ImagesViewer, display_as_slider\n",
        "\n",
        "synth_viz = SyntheticSimpleVisualizer(dataset_loader,\n",
        "                                      dataset_path,\n",
        "                                      worm_is_lighter=worm_is_lighter).generate()\n",
        "img_viewer, img_viewer_plot = ImagesViewer(), ImagesViewer()\n",
        "num_images = 50\n",
        "\n",
        "print(f\"Viewing {num_images} synthetic images.\")\n",
        "tempdir = tempfile.gettempdir()\n",
        "for i in range(num_images):\n",
        "\n",
        "    synth_image, theta = next(synth_viz)\n",
        "\n",
        "    plt.plot(theta)\n",
        "    plt.ylabel(\"theta (rad)\")\n",
        "    plt.xlabel(\"body segment\")\n",
        "    plot_path = os.path.join(tempdir, f\"theta_{i}.png\")\n",
        "    plt.savefig(plot_path)\n",
        "    plt.clf()\n",
        "    img_viewer_plot.add_image_filename(plot_path)\n",
        "\n",
        "    img_viewer.add_image(synth_image)\n",
        "\n",
        "display_as_slider(img_viewer, img_viewer_plot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxhI3CTgfHmI"
      },
      "source": [
        "### Visualize the frame preprocessing\n",
        "\n",
        "You can run the cell below to visualize a sample of the real images after they have been processed : they are cropped (or extended) to the same size which corresponds to the average worm length, and the background and non worm objects pixels are set to a uniform color. In that way, they become visually similar to the synthetic images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AC4cJ0RofHmI"
      },
      "outputs": [],
      "source": [
        "from wormpose.demo.real_simple_visualizer import RealSimpleVisualizer\n",
        "from ipython_utils import ImagesViewer, display_as_slider\n",
        "\n",
        "viz = RealSimpleVisualizer(dataset_loader,\n",
        "                           dataset_path,\n",
        "                           worm_is_lighter=worm_is_lighter).generate()\n",
        "orig_img_viewer, processed_img_viewer = ImagesViewer(), ImagesViewer()\n",
        "\n",
        "max_viz = 100\n",
        "print(f\"Displaying the first {max_viz} frames : original and processed.\")\n",
        "\n",
        "for _ in range(max_viz):\n",
        "    orig_image, processed_image = next(viz)\n",
        "    orig_img_viewer.add_image(orig_image)\n",
        "    processed_img_viewer.add_image(processed_image)\n",
        "\n",
        "display_as_slider(orig_img_viewer, processed_img_viewer)\n",
        "\n",
        "print(f\"The processed images are all set to the size: ({processed_image.shape[0]}px, {processed_image.shape[1]}px).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDc-17YtfHmJ"
      },
      "source": [
        "## Calibration\n",
        "\n",
        "We use a pixel comparison function to compare a real labelled image to its reconstruction as a synthetic image, which assigns a score between 0 (worse) and 1 (perfect reconstruction).\n",
        "This function will be used to evaluate the predictions by comparing them to the original image, and filtering bad results with a threshold.\n",
        "\n",
        "To decide on which threshold to use, we can evaluate this image score function on real labelled images from the dataset. The resulting distribution of scores should be close to 1 if the features are correct. We can visualize the real and the synthetic image that was used for the scoring. Here for example we display 5 examples that represent the range of results from worst to best."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrcTOE_YfHmJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "from wormpose.commands import calibrate\n",
        "from ipython_utils import ImagesViewer\n",
        "\n",
        "video_name, result_file = next(calibrate(dataset_loader,\n",
        "                                         dataset_path,\n",
        "                                         worm_is_lighter=worm_is_lighter,\n",
        "                                         save_images=True))\n",
        "\n",
        "VIEW_SCORES = 5\n",
        "\n",
        "img_viewer = ImagesViewer()\n",
        "with h5py.File(result_file, \"r\") as f:\n",
        "    scores = f['scores'][()]\n",
        "    real_images = f['real_images']\n",
        "    synthetic_images = f['synth_images']\n",
        "\n",
        "    plt.hist(scores, bins=np.arange(0.5, 1, 0.01),\n",
        "             weights=np.ones_like(scores)/len(scores))\n",
        "    plt.xlabel(\"image similarity\")\n",
        "    plt.title(f\"Distribution of image scores for known frames\\n (video: {video_name})\")\n",
        "    plt.show()\n",
        "\n",
        "    sorted_scores = np.argsort(scores)\n",
        "    step = int(len(sorted_scores)/VIEW_SCORES)\n",
        "    sorted_selection_index = [sorted_scores[0]] + sorted_scores[step:-step:step].tolist() + [sorted_scores[-1]]\n",
        "\n",
        "    for index in sorted_selection_index:\n",
        "        im = np.hstack([real_images[index], synthetic_images[index]])\n",
        "        img_viewer.add_image(im)\n",
        "\n",
        "img_viewer.view_as_list(legends=scores[sorted_selection_index])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwzMWc5PfHmJ"
      },
      "source": [
        "## Build the training and evaluation dataset\n",
        "We now build the training dataset which contain images such as above, saved as a binary file \".tfrecord\". We also build an evaluation dataset.\n",
        "\n",
        "We create a small training set of 1000 images for this tutorial. For a more representative training set, increase the value of num_train_samples (the default value is 500k), but the generation will take more time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47e3uEwMfHmJ"
      },
      "outputs": [],
      "source": [
        "from wormpose.commands import generate\n",
        "from ipywidgets import FloatProgress\n",
        "from IPython.display import display\n",
        "\n",
        "fp = FloatProgress(min=0., max=1.)\n",
        "display(fp)\n",
        "\n",
        "gen_progress = generate(dataset_loader,\n",
        "                        dataset_path,\n",
        "                        worm_is_lighter=worm_is_lighter,\n",
        "                        num_train_samples=1000)\n",
        "for progress_value in gen_progress:\n",
        "    fp.value = progress_value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rnHMVn6fHmK"
      },
      "source": [
        "## Check generated tfrecord files\n",
        "\n",
        "We check that the tfrecord files have been generated successfully by viewing the first few images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHWR0kKJfHmK"
      },
      "outputs": [],
      "source": [
        "from glob import glob\n",
        "import os\n",
        "from wormpose.config import default_paths\n",
        "from wormpose.machine_learning import tfrecord_file\n",
        "from ipython_utils import ImagesViewer\n",
        "\n",
        "\n",
        "def view_tfrecord(filename, theta_dims=100, max_viz=100):\n",
        "    img_viewer = ImagesViewer()\n",
        "    for index, record in enumerate(tfrecord_file.read(filename, theta_dims)):\n",
        "        if index >= max_viz:\n",
        "            break\n",
        "        image_data = record[0].numpy()\n",
        "        img_viewer.add_image(image_data)\n",
        "    print(f\"Reading: \\'{filename}\\' ({index} first frames)\")\n",
        "\n",
        "    img_viewer.view_as_slider()\n",
        "\n",
        "train_records = list(sorted(glob(os.path.join(project_dir,\n",
        "                                              default_paths.TRAINING_DATA_DIR,\n",
        "                                              default_paths.SYNTH_TRAIN_DATASET_NAMES.format(index='*')))))\n",
        "print(f\"Training tfrecord files: {len(train_records)} files.\")\n",
        "if len(train_records) > 0 :\n",
        "    view_tfrecord(train_records[0])\n",
        "eval_record = list(glob(os.path.join(project_dir,\n",
        "                                     default_paths.TRAINING_DATA_DIR,\n",
        "                                     default_paths.REAL_EVAL_DATASET_NAMES.format(index='*'))))\n",
        "if len(eval_record) > 0 :\n",
        "    view_tfrecord(eval_record[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qo8OQi4KfHmK"
      },
      "source": [
        "## Train\n",
        "\n",
        "We train the network on the generated data.\n",
        "\n",
        "We only train on 10 epochs for this tutorial, increase the number of epochs for better results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfLRKBKOfHmL"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from wormpose.commands import train\n",
        "\n",
        "if tf.test.gpu_device_name() == '':\n",
        "    print(\"Warning, no GPU available for training, this will be very slow.\")\n",
        "\n",
        "train(dataset_path, epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCG6XY7zfHmL"
      },
      "source": [
        "## Predict\n",
        "\n",
        "We can now predict the full video. We use a score threshold of 0.7 to discard wrong results (see calibration to choose the value of the threshold)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAg1xObhfHmL"
      },
      "outputs": [],
      "source": [
        "from wormpose.commands import predict\n",
        "\n",
        "use_pretrained_network = True\n",
        "if use_pretrained_network: # already trained model for \"sample_data\" only\n",
        "    model_path = os.path.join('wormpose_data', 'models', 'sample_data', 'trained_model.hdf5')\n",
        "else: # will use the default path for the model that was trained in the previous cell\n",
        "    model_path = None\n",
        "\n",
        "predict(dataset_path=dataset_path,\n",
        "        score_threshold=0.7,\n",
        "        model_path=model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BaN-AT7fHmL"
      },
      "source": [
        "We visualize the result by drawing the posture skeleton on top of the original image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oh8RpWBifHmM"
      },
      "outputs": [],
      "source": [
        "from wormpose.commands import visualize\n",
        "\n",
        "visualize(dataset_path, draw_original=False)\n",
        "!find -name 'images_results.zip' -exec sh -c 'unzip -o -d \"${1%.*}\" \"$1\"' _ {} \\;  > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uVHZgLOfHmM"
      },
      "outputs": [],
      "source": [
        "import os, glob\n",
        "from wormpose.config import default_paths\n",
        "from ipython_utils import ImagesViewer\n",
        "\n",
        "MAX_FRAMES = 1000\n",
        "\n",
        "img_filenames = sorted(glob.glob(os.path.join(project_dir, default_paths.RESULTS_DIR, '*','*','*.png')))[:MAX_FRAMES]\n",
        "img_viewer = ImagesViewer()\n",
        "for filename in img_filenames:\n",
        "    img_viewer.add_image_filename(filename)\n",
        "\n",
        "img_viewer.view_as_list(legends=range(len(img_filenames)))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2d34e474e64b417baac08d5d1025a19c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [
              "widget-interact"
            ],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e358278709564ac1b16aaa42f8814595",
              "IPY_MODEL_a7fd41eeac3544088bbf8728d2f07773"
            ],
            "layout": "IPY_MODEL_e657ebcd1dcb4559a8ab951a4f9a7db0"
          }
        },
        "e358278709564ac1b16aaa42f8814595": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntSliderModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "IntSliderView",
            "continuous_update": true,
            "description": "index",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_0175055e87c547e895342cd562fd765a",
            "max": 99,
            "min": 0,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": "d",
            "step": 1,
            "style": "IPY_MODEL_85a0833976d643a3aa3fa2396f487269",
            "value": 23
          }
        },
        "a7fd41eeac3544088bbf8728d2f07773": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_8ad54750071a4514bad4a592475f7065",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "image/png": "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\n",
                  "text/plain": "<IPython.core.display.Image object>"
                },
                "metadata": {}
              }
            ]
          }
        },
        "e657ebcd1dcb4559a8ab951a4f9a7db0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0175055e87c547e895342cd562fd765a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85a0833976d643a3aa3fa2396f487269": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "",
            "handle_color": null
          }
        },
        "8ad54750071a4514bad4a592475f7065": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}